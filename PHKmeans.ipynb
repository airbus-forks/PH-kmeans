{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "s8YUC_itfsBZ"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm, trange\n",
        "from statistics import mean\n",
        "from src.data_utils.generate_synthetic_data import make_point_clouds\n",
        "from gtda.homology import VietorisRipsPersistence\n",
        "from src.data_utils.vectorisation_methods import get_persistence_landscapes, get_betti_curves, get_persistence_images\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "from src.pd_pm_kmeans import PD_KMeans, PM_KMeans\n",
        "from src.data_utils.pd_pm_methods import get_pd, get_grid_width, diag_to_mesr, normalise_pc\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud3hFfAqgipd",
        "outputId": "8c0d5d9d-9059-42c7-cf1f-9d5a671ebb09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (7, 4)\n",
            "┌───────┬──────────┬──────────┬───────────┐\n",
            "│ noise ┆ PL score ┆ PI score ┆ BC_score  │\n",
            "│ ---   ┆ ---      ┆ ---      ┆ ---       │\n",
            "│ i64   ┆ f64      ┆ f64      ┆ f64       │\n",
            "╞═══════╪══════════╪══════════╪═══════════╡\n",
            "│ 0     ┆ 1.0      ┆ 1.0      ┆ 1.0       │\n",
            "│ 1     ┆ 0.89817  ┆ 1.0      ┆ 0.319349  │\n",
            "│ 2     ┆ 0.791828 ┆ 0.731042 ┆ 0.125819  │\n",
            "│ 3     ┆ 1.0      ┆ 1.0      ┆ -0.018542 │\n",
            "│ 4     ┆ 1.0      ┆ 1.0      ┆ 0.306372  │\n",
            "│ 5     ┆ 0.731042 ┆ 0.61674  ┆ 0.35011   │\n",
            "│ 10    ┆ 0.563128 ┆ 0.604474 ┆ 0.089552  │\n",
            "└───────┴──────────┴──────────┴───────────┘\n"
          ]
        }
      ],
      "source": [
        "noise = [0, 1, 2, 3, 4, 5, 10]\n",
        "n_samples_per_class = 10          #sample =  نمونه\n",
        "homology_dimensions = [0, 1, 2]    #dimensions = ابعاد\n",
        "n_clusters = 3\n",
        "\n",
        "landscape_rand = [None] * len(noise)  #landscape = چشم انداز\n",
        "betti_rand = [None] * len(noise)\n",
        "image_rand = [None] * len(noise)\n",
        "\n",
        "km = KMeans(n_clusters=3, init='k-means++')\n",
        "\n",
        "for i, n in enumerate(tqdm(noise)):\n",
        "    # Create synthetic data of 10 samples of 4 classes, circles, spheres, tori and random point clouds\n",
        "    point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=n)\n",
        "    # Compute persistence diagrams\n",
        "    VR = VietorisRipsPersistence(homology_dimensions=homology_dimensions)\n",
        "    diagrams = VR.fit_transform(point_clouds)\n",
        "    # Compute persistence landscapes\n",
        "    p_landscapes = get_persistence_landscapes(point_clouds, diagrams, n_layers=2, n_bins=50)\n",
        "    # Compute betti curves\n",
        "    betti_curves = get_betti_curves(point_clouds, diagrams, n_bins=100)\n",
        "    # Compute persistence images\n",
        "    p_images = get_persistence_images(point_clouds, diagrams, n_bins=10)\n",
        "    # predict labels\n",
        "    landscape_preds = km.fit_predict(p_landscapes)\n",
        "    betti_preds = km.fit_predict(betti_curves)\n",
        "    image_preds = km.fit_predict(p_images)\n",
        "    # Compute rand score for each clustering\n",
        "    landscape_rand[i] = adjusted_rand_score(labels, landscape_preds)\n",
        "    betti_rand[i] = adjusted_rand_score(labels, betti_preds)\n",
        "    image_rand[i] = adjusted_rand_score(labels, image_preds)\n",
        "\n",
        "# print ARI scores in table\n",
        "vector_scores = pl.DataFrame({'noise': noise,\n",
        "                              'PL score': landscape_rand,\n",
        "                              'PI score': image_rand,\n",
        "                              'BC_score': betti_rand})\n",
        "print(vector_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "omKHnrmuhJEs"
      },
      "outputs": [],
      "source": [
        "def persistence_comparison(homology_dimensions: list, noise: int, iters: int):\n",
        "    comparison = []\n",
        "    landscape_scores = []\n",
        "    image_scores = []\n",
        "    # calculate\n",
        "    for _ in trange(iters):\n",
        "        # initialise Persistent Homology\n",
        "        #همسانی پایدار را راه اندازی کنید\n",
        "        VR = VietorisRipsPersistence(homology_dimensions=homology_dimensions)\n",
        "        # generate data with set noise level\n",
        "        # تولید داده با سطح نویز تنظیم شده\n",
        "        point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=noise)\n",
        "        # create persistence diagrams\n",
        "        # ایجاد نمودارهای ماندگاری\n",
        "        diagrams = VR.fit_transform(point_clouds)\n",
        "        # create persistence landscape and image vectors\n",
        "        # بردارهای منظره و تصویر ماندگار ایجاد کنید\n",
        "        p_landscapes = get_persistence_landscapes(point_clouds=point_clouds,\n",
        "                                                  persistence_diagrams=diagrams,\n",
        "                                                  n_layers=2,\n",
        "                                                  n_bins=50)\n",
        "        p_images = get_persistence_images(point_clouds=point_clouds,\n",
        "                                          persistence_diagrams=diagrams,\n",
        "                                          n_bins=10)\n",
        "        # cluster based on vectors\n",
        "        # خوشه بر اساس بردارها\n",
        "        landscape_preds =  km.fit_predict(p_landscapes)\n",
        "        image_preds = km.fit_predict(p_images)\n",
        "        # calculate adjusted rand score for each vectorization\n",
        "        # محاسبه امتیاز رند تعدیل شده برای هر برداری\n",
        "        landscape_score = adjusted_rand_score(labels, landscape_preds)\n",
        "        image_score = adjusted_rand_score(labels, image_preds)\n",
        "        # append scores to list\n",
        "        # نمرات را به لیست اضافه کنید\n",
        "        landscape_scores.append(landscape_score)\n",
        "        image_scores.append(image_score)\n",
        "        # append 1 if PLs outperform PIs\n",
        "        # ضمیمه 1 اگر   PL ها عملکرد بهتری از   PI دارند\n",
        "        if image_score < landscape_score:\n",
        "            comparison.append(1)\n",
        "        else:\n",
        "            comparison.append(0)\n",
        "    print(f\"For noise = {noise}, persistence landscapes outperform persistence images \"\n",
        "          f\"{round(mean(comparison) * 100, 2)}% of the time.\")\n",
        "    print(f\" Average Adjusted Rand Score for Persistence Landscapes: {round(mean(landscape_scores), 3)}\")\n",
        "    print(f\" Std. Adjusted Rand Score for Persistence Landscapes: {round(np.std(landscape_scores), 3)}\")\n",
        "    print(f\" Average Adjusted Rand Score for Persistence Images: {round(mean(image_scores), 3)}\")\n",
        "    print(f\" Std. Adjusted Rand Score for Persistence Images: {round(np.std(image_scores), 3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0pTzylMhVIS",
        "outputId": "5560bd8b-c566-4857-cc3b-51f194b60b2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:37<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For noise = 1.0, persistence landscapes outperform persistence images 63.0% of the time.\n",
            " Average Adjusted Rand Score for Persistence Landscapes: 0.998\n",
            " Std. Adjusted Rand Score for Persistence Landscapes: 0.014\n",
            " Average Adjusted Rand Score for Persistence Images: 0.905\n",
            " Std. Adjusted Rand Score for Persistence Images: 0.085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "persistence_comparison(homology_dimensions=[0, 1, 2], noise=1.0, iters=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8XAiqLKiH6W",
        "outputId": "99d854ae-ecf6-4cff-db68-a2ed9e463106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PD ARI score: 1.0\n"
          ]
        }
      ],
      "source": [
        "# Create simulated data\n",
        "point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=1.0)\n",
        "\n",
        "# Create PDs from simulated data\n",
        "diagrams = []\n",
        "\n",
        "for pc in point_clouds:\n",
        "    norm_pc = normalise_pc(pc)\n",
        "    diag = get_pd(norm_pc)\n",
        "    diagrams.append(diag)\n",
        "\n",
        "# Clustering in Persistence Diagram Space\n",
        "km = PD_KMeans(n_clusters=3, init='kmeans++', random_state=123)\n",
        "pd_preds = km.fit(diagrams)\n",
        "print(f'PD ARI score: {adjusted_rand_score(labels, pd_preds)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Sj9L93ibmv",
        "outputId": "fb74e326-2fd2-4328-8b49-60926a0cfe82"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n",
            "\u001b[1;32m      9\u001b[0m     mesrs\u001b[38;5;241m.\u001b[39mappend(mesr)\n",
            "\u001b[1;32m     11\u001b[0m pm_km \u001b[38;5;241m=\u001b[39m PM_KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans++\u001b[39m\u001b[38;5;124m'\u001b[39m, grid_width\u001b[38;5;241m=\u001b[39mgrid_width)\n",
            "\u001b[0;32m---> 12\u001b[0m pm_preds \u001b[38;5;241m=\u001b[39m \u001b[43mpm_km\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesrs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPM ARI Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madjusted_rand_score(labels,\u001b[38;5;250m \u001b[39mpm_preds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "\n",
            "File \u001b[0;32m~/_package_development/PH-kmeans/src/pd_pm_kmeans.py:150\u001b[0m, in \u001b[0;36mPM_KMeans.fit\u001b[0;34m(self, measures)\u001b[0m\n",
            "\u001b[1;32m    147\u001b[0m prev_centroids \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(measures[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)]\n",
            "\u001b[1;32m    148\u001b[0m grid \u001b[38;5;241m=\u001b[39m mesh_gen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_width)\n",
            "\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp \u001b[38;5;241m=\u001b[39m \u001b[43mdist_mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(measures, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n",
            "\n",
            "File \u001b[0;32m~/_package_development/PH-kmeans/PD_subsample/ApproxPH.py:98\u001b[0m, in \u001b[0;36mdist_mat\u001b[0;34m(grid, power_index)\u001b[0m\n",
            "\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mat_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
            "\u001b[1;32m     97\u001b[0m \t\u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mat_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
            "\u001b[0;32m---> 98\u001b[0m \t\tM[i,j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mabs\u001b[39m(grid[i][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m-\u001b[39m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]),\\\n",
            "\u001b[1;32m     99\u001b[0m \t\t\t\t\t\u001b[38;5;28mabs\u001b[39m(grid[i][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39mgrid[j][\u001b[38;5;241m1\u001b[39m])])\n",
            "\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# append the diagnal\u001b[39;00m\n",
            "\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(mat_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
            "\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "# get appropriate grid_width from list of PDs\n",
        "grid_width = get_grid_width(diagrams)\n",
        "\n",
        "# create list of PMs from PDs\n",
        "mesrs = []\n",
        "for diag in diagrams:\n",
        "    concat_diag = np.concatenate(diag)\n",
        "    mesr, _ = diag_to_mesr(concat_diag, unit_mass=1, grid_width=grid_width)\n",
        "    mesrs.append(mesr)\n",
        "\n",
        "pm_km = PM_KMeans(n_clusters=3, init='kmeans++', grid_width=grid_width)\n",
        "pm_preds = pm_km.fit(mesrs)\n",
        "\n",
        "print(f'PM ARI Score: {adjusted_rand_score(labels, pm_preds)}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
