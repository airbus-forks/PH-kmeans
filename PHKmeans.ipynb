{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s8YUC_itfsBZ"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import polars as pl\n",
        "from tqdm import tqdm, trange\n",
        "from statistics import mean\n",
        "from src.data_utils.generate_synthetic_data import make_point_clouds\n",
        "from gtda.homology import VietorisRipsPersistence\n",
        "from src.data_utils.vectorisation_methods import get_persistence_landscapes, get_betti_curves, get_persistence_images\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud3hFfAqgipd",
        "outputId": "8c0d5d9d-9059-42c7-cf1f-9d5a671ebb09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: (7, 4)\n",
            "┌───────┬──────────┬──────────┬──────────┐\n",
            "│ noise ┆ PL score ┆ PI score ┆ BC_score │\n",
            "│ ---   ┆ ---      ┆ ---      ┆ ---      │\n",
            "│ i64   ┆ f64      ┆ f64      ┆ f64      │\n",
            "╞═══════╪══════════╪══════════╪══════════╡\n",
            "│ 0     ┆ 1.0      ┆ 1.0      ┆ 1.0      │\n",
            "│ 1     ┆ 1.0      ┆ 0.808229 ┆ 0.057585 │\n",
            "│ 2     ┆ 1.0      ┆ 1.0      ┆ 0.278556 │\n",
            "│ 3     ┆ 1.0      ┆ 0.423348 ┆ 0.146461 │\n",
            "│ 4     ┆ 1.0      ┆ 0.808229 ┆ 0.33429  │\n",
            "│ 5     ┆ 0.667145 ┆ 0.89817  ┆ 0.233598 │\n",
            "│ 10    ┆ 0.808229 ┆ 0.440262 ┆ 0.199005 │\n",
            "└───────┴──────────┴──────────┴──────────┘\n"
          ]
        }
      ],
      "source": [
        "noise = [0, 1, 2, 3, 4, 5, 10]\n",
        "n_samples_per_class = 10          #sample =  نمونه\n",
        "homology_dimensions = [0, 1, 2]    #dimensions = ابعاد\n",
        "n_clusters = 3\n",
        "\n",
        "landscape_rand = [None] * len(noise)  #landscape = چشم انداز\n",
        "betti_rand = [None] * len(noise)\n",
        "image_rand = [None] * len(noise)\n",
        "\n",
        "km = KMeans(n_clusters=3, init='k-means++')\n",
        "\n",
        "for i, n in enumerate(noise):\n",
        "    # Create synthetic data of 10 samples of 4 classes, circles, spheres, tori and random point clouds\n",
        "    point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=n)\n",
        "    # Compute persistence diagrams\n",
        "    VR = VietorisRipsPersistence(homology_dimensions=homology_dimensions)\n",
        "    diagrams = VR.fit_transform(point_clouds)\n",
        "    # Compute persistence landscapes\n",
        "    p_landscapes = get_persistence_landscapes(point_clouds, diagrams, n_layers=2, n_bins=50)\n",
        "    # Compute betti curves\n",
        "    betti_curves = get_betti_curves(point_clouds, diagrams, n_bins=100)\n",
        "    # Compute persistence images\n",
        "    p_images = get_persistence_images(point_clouds, diagrams, n_bins=10)\n",
        "    # predict labels\n",
        "    landscape_preds = km.fit_predict(p_landscapes)\n",
        "    betti_preds = km.fit_predict(betti_curves)\n",
        "    image_preds = km.fit_predict(p_images)\n",
        "    # Compute rand score for each clustering\n",
        "    landscape_rand[i] = adjusted_rand_score(labels, landscape_preds)\n",
        "    betti_rand[i] = adjusted_rand_score(labels, betti_preds)\n",
        "    image_rand[i] = adjusted_rand_score(labels, image_preds)\n",
        "\n",
        "# print ARI scores in table\n",
        "vector_scores = pl.DataFrame({'noise': noise,\n",
        "                              'PL score': landscape_rand,\n",
        "                              'PI score': image_rand,\n",
        "                              'BC_score': betti_rand})\n",
        "print(vector_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "omKHnrmuhJEs"
      },
      "outputs": [],
      "source": [
        "def persistence_comparison(homology_dimensions: list, noise: int, iters: int):\n",
        "    comparison = []\n",
        "    landscape_scores = []\n",
        "    image_scores = []\n",
        "    # calculate\n",
        "    for _ in trange(iters):\n",
        "        # initialise Persistent Homology\n",
        "        #همسانی پایدار را راه اندازی کنید\n",
        "        VR = VietorisRipsPersistence(homology_dimensions=homology_dimensions)\n",
        "        # generate data with set noise level\n",
        "        # تولید داده با سطح نویز تنظیم شده\n",
        "        point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=noise)\n",
        "        # create persistence diagrams\n",
        "        # ایجاد نمودارهای ماندگاری\n",
        "        diagrams = VR.fit_transform(point_clouds)\n",
        "        # create persistence landscape and image vectors\n",
        "        # بردارهای منظره و تصویر ماندگار ایجاد کنید\n",
        "        p_landscapes = get_persistence_landscapes(point_clouds=point_clouds,\n",
        "                                                  persistence_diagrams=diagrams,\n",
        "                                                  n_layers=2,\n",
        "                                                  n_bins=50)\n",
        "        p_images = get_persistence_images(point_clouds=point_clouds,\n",
        "                                          persistence_diagrams=diagrams,\n",
        "                                          n_bins=10)\n",
        "        # cluster based on vectors\n",
        "        # خوشه بر اساس بردارها\n",
        "        landscape_preds =  km.fit_predict(p_landscapes)\n",
        "        image_preds = km.fit_predict(p_images)\n",
        "        # calculate adjusted rand score for each vectorization\n",
        "        # محاسبه امتیاز رند تعدیل شده برای هر برداری\n",
        "        landscape_score = adjusted_rand_score(labels, landscape_preds)\n",
        "        image_score = adjusted_rand_score(labels, image_preds)\n",
        "        # append scores to list\n",
        "        # نمرات را به لیست اضافه کنید\n",
        "        landscape_scores.append(landscape_score)\n",
        "        image_scores.append(image_score)\n",
        "        # append 1 if PLs outperform PIs\n",
        "        # ضمیمه 1 اگر   PL ها عملکرد بهتری از   PI دارند\n",
        "        if image_score < landscape_score:\n",
        "            comparison.append(1)\n",
        "        else:\n",
        "            comparison.append(0)\n",
        "    print(f\"For noise = {noise}, persistence landscapes outperform persistence images \"\n",
        "          f\"{round(mean(comparison) * 100, 2)}% of the time.\")\n",
        "    print(f\" Average Adjusted Rand Score for Persistence Landscapes: {round(mean(landscape_scores), 3)}\")\n",
        "    print(f\" Std. Adjusted Rand Score for Persistence Landscapes: {round(np.std(landscape_scores), 3)}\")\n",
        "    print(f\" Average Adjusted Rand Score for Persistence Images: {round(mean(image_scores), 3)}\")\n",
        "    print(f\" Std. Adjusted Rand Score for Persistence Images: {round(np.std(image_scores), 3)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0pTzylMhVIS",
        "outputId": "5560bd8b-c566-4857-cc3b-51f194b60b2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:37<00:00,  2.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For noise = 1.0, persistence landscapes outperform persistence images 67.0% of the time.\n",
            " Average Adjusted Rand Score for Persistence Landscapes: 0.998\n",
            " Std. Adjusted Rand Score for Persistence Landscapes: 0.014\n",
            " Average Adjusted Rand Score for Persistence Images: 0.892\n",
            " Std. Adjusted Rand Score for Persistence Images: 0.096\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "persistence_comparison(homology_dimensions=[0, 1, 2], noise=1.0, iters=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8XAiqLKiH6W",
        "outputId": "99d854ae-ecf6-4cff-db68-a2ed9e463106"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
            "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n",
            "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpd_pm_kmeans\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PD_KMeans, PM_KMeans\n",
            "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpd_pm_methods\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create simulated data\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m~/_package_development/PH-kmeans/src/pd_pm_kmeans.py:7\u001b[0m\n",
            "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgudhi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwasserstein\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbarycenter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lagrangian_barycenter\n",
            "\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpd_pm_methods\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPD_subsample\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mApproxPH\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mkmeans_plusplus\u001b[39m(data: \u001b[38;5;28mlist\u001b[39m, n_clusters: \u001b[38;5;28mint\u001b[39m, data_type: \u001b[38;5;28mstr\u001b[39m, random_state: \u001b[38;5;28mint\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
            "\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
            "\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Function performs the k-means++ initialisation algorithm, returning n_clusters number of centroids from the given\u001b[39;00m\n",
            "\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    data.\u001b[39;00m\n",
            "\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "\n",
            "File \u001b[0;32m~/_package_development/PH-kmeans/PD_subsample/ApproxPH.py:3\u001b[0m\n",
            "\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n",
            "\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgudhi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgd\u001b[39;00m\n",
            "\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
            "\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n",
            "\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mot\u001b[39;00m\n",
            "\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "from src.pd_pm_kmeans import PD_KMeans, PM_KMeans\n",
        "from src.data_utils.pd_pm_methods import *\n",
        "\n",
        "\n",
        "# Create simulated data\n",
        "point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=1.0)\n",
        "\n",
        "# Create PDs from simulated data\n",
        "diagrams = []\n",
        "\n",
        "for pc in point_clouds:\n",
        "    norm_pc = normalise_pc(pc)\n",
        "    diag = get_pd(norm_pc)\n",
        "    diagrams.append(diag)\n",
        "\n",
        "# Clustering in Persistence Diagram Space\n",
        "km = PD_KMeans(n_clusters=3, init='kmeans++', random_state=123)\n",
        "pd_preds = km.fit(diagrams)\n",
        "print(f'PD ARI score: {adjusted_rand_score(labels, pd_preds)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Sj9L93ibmv",
        "outputId": "fb74e326-2fd2-4328-8b49-60926a0cfe82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PM ARI Score: 0.8981703936425799\n"
          ]
        }
      ],
      "source": [
        "# get appropriate grid_width from list of PDs\n",
        "grid_width = get_grid_width(diagrams)\n",
        "\n",
        "# create list of PMs from PDs\n",
        "mesrs = []\n",
        "for diag in diagrams:\n",
        "    concat_diag = np.concatenate(diag)\n",
        "    mesr, _ = diag_to_mesr(concat_diag, unit_mass=1, grid_width=grid_width)\n",
        "    mesrs.append(mesr)\n",
        "\n",
        "pm_km = PM_KMeans(n_clusters=3, init='kmeans++', grid_width=grid_width)\n",
        "pm_preds = pm_km.fit(mesrs)\n",
        "\n",
        "print(f'PM ARI Score: {adjusted_rand_score(labels, pm_preds)}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
