{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Synthetic Data Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisation Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm import tqdm, trange\n",
    "from statistics import mean\n",
    "from data_utils.generate_synthetic_data import make_point_clouds\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from data_utils.vectorisation_methods import get_persistence_landscapes, get_betti_curves, get_persistence_images\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# imports\n",
    "from pd_pm_kmeans import PD_KMeans, PM_KMeans\n",
    "from src.data_utils.pd_pm_methods import get_pd, get_grid_width, diag_to_mesr, normalise_pc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we cluster the vector representations of the persistence diagrams of synthetic data for varying levels of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters for clustering with varying noise\n",
    "noise = [0, 1, 2, 3, 4, 5, 10]\n",
    "n_samples_per_class = 10\n",
    "homology_dimensions = [0, 1, 2]\n",
    "n_clusters = 3\n",
    "\n",
    "landscape_rand = [None] * len(noise)\n",
    "betti_rand = [None] * len(noise)\n",
    "image_rand = [None] * len(noise)\n",
    "\n",
    "km = KMeans(n_clusters=3, init='k-means++')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (7, 4)\n",
      "┌───────┬──────────┬──────────┬──────────┐\n",
      "│ noise ┆ PL score ┆ PI score ┆ BC_score │\n",
      "│ ---   ┆ ---      ┆ ---      ┆ ---      │\n",
      "│ i64   ┆ f64      ┆ f64      ┆ f64      │\n",
      "╞═══════╪══════════╪══════════╪══════════╡\n",
      "│ 0     ┆ 1.0      ┆ 1.0      ┆ 1.0      │\n",
      "│ 1     ┆ 1.0      ┆ 0.89817  ┆ 0.039337 │\n",
      "│ 2     ┆ 0.89817  ┆ 1.0      ┆ 0.129542 │\n",
      "│ 3     ┆ 0.8017   ┆ 0.89817  ┆ 0.126055 │\n",
      "│ 4     ┆ 0.436705 ┆ 0.731042 ┆ 0.136749 │\n",
      "│ 5     ┆ 0.70523  ┆ 0.698192 ┆ 0.228599 │\n",
      "│ 10    ┆ 0.520095 ┆ 0.440262 ┆ 0.126347 │\n",
      "└───────┴──────────┴──────────┴──────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate adjusted rand scores for clustering of data with varying noise\n",
    "for i, n in enumerate(tqdm(noise)):\n",
    "    # Create synthetic data of 10 samples of 4 classes, circles, spheres, tori and random point clouds\n",
    "    point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=n)\n",
    "    # Compute persistence diagrams\n",
    "    VR = VietorisRipsPersistence(homology_dimensions=homology_dimensions)\n",
    "    diagrams = VR.fit_transform(point_clouds)\n",
    "    # Compute persistence landscapes\n",
    "    p_landscapes = get_persistence_landscapes(point_clouds, diagrams, n_layers=2, n_bins=50)\n",
    "    # Compute betti curves\n",
    "    betti_curves = get_betti_curves(point_clouds, diagrams, n_bins=100)\n",
    "    # Compute persistence images\n",
    "    p_images = get_persistence_images(point_clouds, diagrams, n_bins=10)\n",
    "    # predict labels\n",
    "    landscape_preds = km.fit_predict(p_landscapes)\n",
    "    betti_preds = km.fit_predict(betti_curves)\n",
    "    image_preds = km.fit_predict(p_images)\n",
    "    # Compute rand score for each clustering\n",
    "    landscape_rand[i] = adjusted_rand_score(labels, landscape_preds)\n",
    "    betti_rand[i] = adjusted_rand_score(labels, betti_preds)\n",
    "    image_rand[i] = adjusted_rand_score(labels, image_preds)\n",
    "\n",
    "# print ARI scores in table\n",
    "vector_scores = pl.DataFrame({'noise': noise,\n",
    "                              'PL score': landscape_rand,\n",
    "                              'PI score': image_rand,\n",
    "                              'BC_score': betti_rand})\n",
    "print(vector_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We compare the clustering output of persistence landscapes and persistence images by repeating the experiment on variations of the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def persistence_comparison(homology_dimensions: list, noise: int, iters: int):\n",
    "    comparison = []\n",
    "    landscape_scores = []\n",
    "    image_scores = []\n",
    "    # calculate\n",
    "    for _ in trange(iters):\n",
    "        # initialise Persistent Homology\n",
    "        VR = VietorisRipsPersistence(homology_dimensions=homology_dimensions)\n",
    "        # generate data with set noise level\n",
    "        point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=noise)\n",
    "        # create persistence diagrams\n",
    "        diagrams = VR.fit_transform(point_clouds)\n",
    "        # create persistence landscape and image vectors\n",
    "        p_landscapes = get_persistence_landscapes(point_clouds=point_clouds,\n",
    "                                                  persistence_diagrams=diagrams,\n",
    "                                                  n_layers=2,\n",
    "                                                  n_bins=50)\n",
    "        p_images = get_persistence_images(point_clouds=point_clouds,\n",
    "                                          persistence_diagrams=diagrams,\n",
    "                                          n_bins=10)\n",
    "        # cluster based on vectors\n",
    "        landscape_preds =  km.fit_predict(p_landscapes)\n",
    "        image_preds = km.fit_predict(p_images)\n",
    "        # calculate adjusted rand score for each vectorization\n",
    "        landscape_score = adjusted_rand_score(labels, landscape_preds)\n",
    "        image_score = adjusted_rand_score(labels, image_preds)\n",
    "        # append scores to list\n",
    "        landscape_scores.append(landscape_score)\n",
    "        image_scores.append(image_score)\n",
    "        # append 1 if PLs outperform PIs\n",
    "        if image_score < landscape_score:\n",
    "            comparison.append(1)\n",
    "        else:\n",
    "            comparison.append(0)\n",
    "    print(f\"For noise = {noise}, persistence landscapes outperform persistence images \"\n",
    "          f\"{round(mean(comparison) * 100, 2)}% of the time.\")\n",
    "    print(f\" Average Adjusted Rand Score for Persistence Landscapes: {round(mean(landscape_scores), 3)}\")\n",
    "    print(f\" Std. Adjusted Rand Score for Persistence Landscapes: {round(np.std(landscape_scores), 3)}\")\n",
    "    print(f\" Average Adjusted Rand Score for Persistence Images: {round(mean(image_scores), 3)}\")\n",
    "    print(f\" Std. Adjusted Rand Score for Persistence Images: {round(np.std(image_scores), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:37<00:00,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For noise = 1.0, persistence landscapes outperform persistence images 64.0% of the time.\n",
      " Average Adjusted Rand Score for Persistence Landscapes: 0.996\n",
      " Std. Adjusted Rand Score for Persistence Landscapes: 0.02\n",
      " Average Adjusted Rand Score for Persistence Images: 0.898\n",
      " Std. Adjusted Rand Score for Persistence Images: 0.093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# example of persistence landscape/vector comparison for noise = 1.0\n",
    "\n",
    "persistence_comparison(homology_dimensions=[0, 1, 2], noise=1.0, iters=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Persistence Diagram Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this section we demonstrate running the PD and PM K-means clustering algorithms on simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:11<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create simulated data\n",
    "point_clouds, labels = make_point_clouds(n_samples_per_class, n_points=10, noise=1.0)\n",
    "\n",
    "# Create PDs from simulated data\n",
    "diagrams = []\n",
    "\n",
    "for pc in tqdm(point_clouds):\n",
    "    norm_pc = normalise_pc(pc)\n",
    "    diag = get_pd(norm_pc)\n",
    "    diagrams.append(diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PD ARI score: 0.7661290322580645\n"
     ]
    }
   ],
   "source": [
    "# Clustering in Persistence Diagram Space\n",
    "km = PD_KMeans(n_clusters=5, init='kmeans++', random_state=123)\n",
    "pd_preds = km.fit(diagrams)\n",
    "print(f'PD ARI score: {adjusted_rand_score(labels, pd_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering Persistence Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mesh_gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n",
      "\u001b[1;32m      9\u001b[0m     mesrs\u001b[38;5;241m.\u001b[39mappend(mesr)\n",
      "\u001b[1;32m     11\u001b[0m pm_km \u001b[38;5;241m=\u001b[39m PM_KMeans(n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkmeans++\u001b[39m\u001b[38;5;124m'\u001b[39m, grid_width\u001b[38;5;241m=\u001b[39mgrid_width)\n",
      "\u001b[0;32m---> 12\u001b[0m pm_preds \u001b[38;5;241m=\u001b[39m \u001b[43mpm_km\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesrs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPM ARI Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madjusted_rand_score(labels,\u001b[38;5;250m \u001b[39mpm_preds)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\n",
      "File \u001b[0;32m~/_package_development/PH-kmeans/src/pd_pm_kmeans.py:147\u001b[0m, in \u001b[0;36mPM_KMeans.fit\u001b[0;34m(self, measures)\u001b[0m\n",
      "\u001b[1;32m    145\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;32m    146\u001b[0m prev_centroids \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mzeros(measures[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)]\n",
      "\u001b[0;32m--> 147\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[43mmesh_gen\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_width)\n",
      "\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp \u001b[38;5;241m=\u001b[39m dist_mat(grid, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mesh_gen' is not defined"
     ]
    }
   ],
   "source": [
    "# get appropriate grid_width from list of PDs\n",
    "grid_width = get_grid_width(diagrams)\n",
    "\n",
    "# create list of PMs from PDs\n",
    "mesrs = []\n",
    "for diag in diagrams:\n",
    "    concat_diag = np.concatenate(diag)\n",
    "    mesr, _ = diag_to_mesr(concat_diag, unit_mass=1, grid_width=grid_width)\n",
    "    mesrs.append(mesr)\n",
    "\n",
    "pm_km = PM_KMeans(n_clusters=3, init='kmeans++', grid_width=grid_width)\n",
    "pm_preds = pm_km.fit(mesrs)\n",
    "\n",
    "print(f'PM ARI Score: {adjusted_rand_score(labels, pm_preds)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscenv",
   "language": "python",
   "name": "mscenv"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
